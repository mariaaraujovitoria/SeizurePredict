{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab4b515b",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Imports, variables, functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9de958e9",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# -- IMPORTS --\n",
    "\n",
    "import scipy.io\n",
    "from pyedflib import highlevel\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from itertools import groupby\n",
    "import csv\n",
    "import pickle\n",
    "from scipy.signal import butter, sosfilt, sosfiltfilt, sosfreqz\n",
    "from scipy.signal import freqz, iirnotch, filtfilt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "import random\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy import signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3b2d4a7",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# -- ENVIRONMENT VARIABLES --\n",
    "\n",
    "sample_rate = sampling_rate = 256\n",
    "sec = 10\n",
    "len_window = sample_rate*sec\n",
    "overlap = 5\n",
    "threshold = 2*sample_rate\n",
    "sample_rate_downsample = int(0.1*sample_rate)\n",
    "len_window_downsample = sample_rate_downsample*sec\n",
    "\n",
    "patients = list(range(1, 80))\n",
    "patient_with_issue = [4, 29, 50] \n",
    "for i in patient_with_issue:\n",
    "    patients.remove(i)\n",
    "patients.remove(5)\n",
    "\n",
    "# Load annotation file\n",
    "annt = scipy.io.loadmat('../raw_data/annotations_2017.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a91cb2d1",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## -- PREPROCESSING FUNCTIONS --\n",
    "\n",
    "# Highpass filter\n",
    "def highpass_filter(signals, sampling_rate, hp_frequency = 0.1):\n",
    "    sos = butter(N = 3, Wn = hp_frequency, btype=\"highpass\",fs=sampling_rate, output=\"sos\")\n",
    "    filter_hp = sosfiltfilt(sos, signals)\n",
    "    return filter_hp\n",
    "\n",
    "# Powerline filter\n",
    "def notch_filter(signals, sampling_rate, notch_frequency = 50, quality_factor = 30):\n",
    "    w0 = notch_frequency/(sampling_rate/2)\n",
    "    b_notch, a_notch = iirnotch(w0, quality_factor)\n",
    "    filter_notch = filtfilt(b_notch, a_notch, signals, axis = -1)\n",
    "    return filter_notch\n",
    "\n",
    "# Create our own scaler\n",
    "class CustomTranformer(TransformerMixin, BaseEstimator): \n",
    "    # BaseEstimator generates the get_params() and set_params() methods that all Pipelines require\n",
    "    # TransformerMixin creates the fit_transform() method from fit() and transform()\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        self.means = X.mean()\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        norm_features = X - self.means\n",
    "        return norm_features\n",
    "\n",
    "# Combination of all filters and Scaler\n",
    "def filter_signals(signals, sampling_rate, scaler, hp_frequency = 0.1, notch_frequency = 50, quality_factor = 30):\n",
    "    filter_hp = highpass_filter(signals, sampling_rate)\n",
    "    filter_notch = notch_filter(filter_hp, sampling_rate, notch_frequency, quality_factor)\n",
    "    final_signal = scaler.fit_transform(filter_notch)\n",
    "    return final_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b688fa19",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## -- LABEL FUNCTIONS --\n",
    "\n",
    "# Format the EEG \n",
    "def eeg_formated(signals, names_ele):\n",
    "    data_signals = signals.T # transpose the signals from datapoints\n",
    "    data_signals = pd.DataFrame(data_signals) # create a pandas dataframe\n",
    "    \n",
    "    data_signals.columns = names_ele # rename columns\n",
    "    \n",
    "    return data_signals\n",
    "\n",
    "# Format the annotations\n",
    "def diagnosis(n):\n",
    "    patient_A=annt[\"annotat_new\"][0][n-1][0]\n",
    "    patient_B=annt[\"annotat_new\"][0][n-1][1]\n",
    "    patient_C=annt[\"annotat_new\"][0][n-1][2]\n",
    "    \n",
    "    #converting seconds to datapoints\n",
    "\n",
    "    patient_A=patient_A.tolist()\n",
    "    patient_B=patient_B.tolist()\n",
    "    patient_C=patient_C.tolist()\n",
    "    \n",
    "    patient_A_dtp=[]\n",
    "    patient_B_dtp=[]\n",
    "    patient_C_dtp=[]  \n",
    "    for elem in patient_A:\n",
    "        for i in range(sampling_rate):\n",
    "            patient_A_dtp.append(elem) \n",
    "    for elem in patient_B:\n",
    "        for i in range(sampling_rate):\n",
    "            patient_B_dtp.append(elem)\n",
    "        \n",
    "    for elem in patient_C:\n",
    "        for i in range(sampling_rate):\n",
    "            patient_C_dtp.append(elem)\n",
    "            \n",
    "    target_=pd.DataFrame({\"Diagnosis A\":patient_A_dtp,\"Diagnosis B\":patient_B_dtp,\"Diagnosis C\":patient_C_dtp})\n",
    "    \n",
    "    return target_  \n",
    "\n",
    "# Create target variables when seizures lasts at least 10\n",
    "def is_seizure(df):\n",
    "    \n",
    "    threshold = sampling_rate*10\n",
    "    \n",
    "    df['is_seizure_A'] = df[\"Diagnosis A\"].groupby((df[\"Diagnosis A\"] != df[\"Diagnosis A\"].shift()).cumsum()).transform('size') * df[\"Diagnosis A\"]\n",
    "    df['is_seizure_A'] = (df['is_seizure_A'] > threshold).astype(int)\n",
    "    \n",
    "    df['is_seizure_B'] = df[\"Diagnosis B\"].groupby((df[\"Diagnosis B\"] != df[\"Diagnosis B\"].shift()).cumsum()).transform('size') * df[\"Diagnosis B\"]\n",
    "    df['is_seizure_B'] = (df['is_seizure_B'] > threshold).astype(int)\n",
    "    \n",
    "    df['is_seizure_C'] = df[\"Diagnosis C\"].groupby((df[\"Diagnosis C\"] != df[\"Diagnosis C\"].shift()).cumsum()).transform('size') * df[\"Diagnosis C\"]\n",
    "    df['is_seizure_C'] = (df['is_seizure_C'] > threshold).astype(int)\n",
    "    \n",
    "    return df \n",
    "\n",
    "# Create final target\n",
    "def create_target(df):\n",
    "    df['is_seizure_target'] = np.where(df['is_seizure_A'] + df['is_seizure_B'] + df['is_seizure_C'] >= 2, 1, 0)\n",
    "    return df\n",
    "\n",
    "# Remove useless\n",
    "def remove_useless_columns(df):\n",
    "    df.drop(columns=['Diagnosis A', 'Diagnosis B', 'Diagnosis C', 'is_seizure_A', 'is_seizure_B', 'is_seizure_C', 'ECG EKG', 'Resp Effort'], inplace=True)\n",
    "    return df\n",
    "\n",
    "# Final function to label\n",
    "def label_data(path_raw_data, signals_preprocessed, n):\n",
    "    \n",
    "    signals, signal_headers, header = highlevel.read_edf(path_raw_data)\n",
    "    \n",
    "    names_ele = [signal_headers[iele]['label'] for iele in range(signals.shape[0])] # extract electrode names\n",
    "    \n",
    "    eeg_patient = eeg_formated(signals_preprocessed, names_ele) # format the ECG\n",
    "    eeg_patient.rename(columns={'ECG EKG-REF':'ECG EKG', 'Resp Effort-REF':'Resp Effort'}, inplace=True)\n",
    "    \n",
    "    diagnosis_patient = diagnosis(n) # format the diagnosis\n",
    "    \n",
    "    data_patient = pd.merge(left=eeg_patient, right=diagnosis_patient, how='left', left_index=True, right_index=True) # merge ecg and diagnosis\n",
    "    \n",
    "    is_seizure(data_patient)\n",
    "    create_target(data_patient)\n",
    "    remove_useless_columns(data_patient)\n",
    "    \n",
    "    return data_patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3d6e361",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## -- FEATURE ENGINEERING --\n",
    "\n",
    "def flatten(window_df):\n",
    "    if len(np.unique(window_df.iloc[:,-1])) == 1:\n",
    "        target = window_df.iloc[0,-1]\n",
    "    elif np.unique(window_df.iloc[:,-1],return_counts=True)[1][1] >= threshold:\n",
    "        target = 1\n",
    "    else:\n",
    "        target = 0\n",
    "    t_df = window_df.drop(columns = \"target\").transpose()\n",
    "    flatten = pd.DataFrame(np.array(t_df).reshape(1,t_df.shape[0]*t_df.shape[1]))\n",
    "    flatten[\"Target\"] = target\n",
    "    return flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c1cf14d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## -- MAIN FUNCTIONS --\n",
    "\n",
    "def preprocess_and_label(path_raw_data, scaler, patient_number, Fournier=False):\n",
    "    \n",
    "    # Load raw data\n",
    "    signals, signal_headers, header = highlevel.read_edf(path_raw_data)\n",
    "    \n",
    "    # Preprocess data \n",
    "    signals_preprocessed = filter_signals(signals, sampling_rate, scaler, hp_frequency = 0.1, notch_frequency = 50, quality_factor = 30)\n",
    "    \n",
    "    if Fournier == True:\n",
    "        signals_preprocessed = pd.DataFrame(np.array([abs(rfft(signals_preprocessed[i])) for i in range(len(signals_preprocessed))]))\n",
    "        \n",
    "    # Label data\n",
    "    df = label_data(path_raw_data, signals_preprocessed, patient_number)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def downsampling(df):\n",
    "    df_downsample = pd.DataFrame()\n",
    "    all_df = pd.DataFrame()\n",
    "    target_col = df.iloc[:,-1]\n",
    "    num = int(0.1*sample_rate)\n",
    "    t = 256\n",
    "    for i, column in enumerate(df.columns[:-1]):\n",
    "        df_downsample = pd.DataFrame()\n",
    "        for j in range(0,len(df)-sample_rate,sample_rate):\n",
    "            x = np.array(df.iloc[j:j+sample_rate,i])\n",
    "            x_resampled = pd.DataFrame(signal.resample(x, num), index=range(int(j/10),int(j/10)+num))\n",
    "            df_downsample= pd.concat([df_downsample,x_resampled])\n",
    "        all_df[column] = np.array(df_downsample).reshape(1,-1)[0]\n",
    "    target = []\n",
    "    for t in range(0,len(target_col)-256,sample_rate):\n",
    "        for n in range(num):\n",
    "            target.append(target_col[t])\n",
    "    all_df[\"target\"] = target\n",
    "    return all_df\n",
    "\n",
    "def flatten_dataframe(df):\n",
    "    data = np.array([flatten(df.iloc[i:i+len_window_downsample]) for i in range(0,len(df)-len_window_downsample, overlap*sample_rate_downsample)])\n",
    "    r=data.shape[0]\n",
    "    c=data.shape[2]\n",
    "    data = pd.DataFrame(data.reshape(r,c))\n",
    "    return data\n",
    "\n",
    "def concat_dataframes(dictionnary_of_dataframes):\n",
    "    df = pd.concat([dictionnary_of_dataframes[i] for i in dictionnary_of_dataframes.keys()])\n",
    "    return df\n",
    "\n",
    "def create_x_and_y(df):\n",
    "    X = df.iloc[:,:-1]\n",
    "    y = df.iloc[:,-1]\n",
    "    return X,y\n",
    "\n",
    "def oversampling(X, y): \n",
    "    sm = SMOTE(sampling_strategy='minority', random_state=7)\n",
    "    X, y = sm.fit_resample(X, y)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3383cf",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ba3dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {}\n",
    "for i in patients:\n",
    "    df_i = preprocess_and_label(f\"../raw_data/eeg{i}.edf\", CustomTranformer(), i, Fournier=False)\n",
    "    d[i] = df_i\n",
    "    d[i].columns= d[i].columns.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264431f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "d[2].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992a6b26",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c40a49",
   "metadata": {},
   "source": [
    "## Downsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ff0bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_downsample = {}\n",
    "\n",
    "for i in patients:\n",
    "    d_downsample[i] = downsampling(d[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0905ce2",
   "metadata": {},
   "source": [
    "## Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b201cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_downsample_flat = {}\n",
    "\n",
    "for i in patients:\n",
    "    d_downsample_flat[i] = flatten_dataframe(d_downsample[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3625613",
   "metadata": {},
   "source": [
    "## Concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9959e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = concat_dataframes(d_downsample_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d739c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = create_x_and_y(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8caa07d5",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f85dc81",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc40606",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/Test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd679523",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balancing\n",
    "X_train, y_train = oversampling(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c349cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit model\n",
    "model = SVC(kernel='linear', C=0.001) \n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ffcca5",
   "metadata": {},
   "source": [
    "## Test on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe038610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "y_pred_test = model.predict(X_test)\n",
    "\n",
    "test_score = accuracy_score(y_test, y_pred_test)\n",
    "test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1d9bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "test_results_df = pd.DataFrame({\"actual\": y_test,\n",
    "                           \"predicted\": y_pred_test})\n",
    "    \n",
    "test_confusion_matrix = pd.crosstab(index= test_results_df['actual'],\n",
    "                               columns = test_results_df['predicted'])\n",
    "    \n",
    "test_confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbcb3057",
   "metadata": {},
   "source": [
    "## Test on new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e90cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess and label new data\n",
    "path_raw_new_data = \"../raw_data/eeg5.edf\"\n",
    "df_new = preprocess_and_label(path_raw_new_data, CustomTranformer(), 5, Fournier=False)\n",
    "\n",
    "# Downsampling new data\n",
    "df_new_downsample = downsampling(df_new)\n",
    "\n",
    "# Flatten new data\n",
    "df_new_downsample_flat = flatten_dataframe(df_new_downsample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698d4111",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "y_true = df_new_downsample_flat.iloc[:,-1]\n",
    "y_pred = model.predict(df_new_downsample_flat.iloc[:,:-1])\n",
    "\n",
    "new_score = accuracy_score(y_true, y_pred)\n",
    "new_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8188f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "new_results_df = pd.DataFrame({\"actual\": y_true,\n",
    "                           \"predicted\": y_pred})\n",
    "    \n",
    "new_confusion_matrix = pd.crosstab(index= new_results_df['actual'],\n",
    "                               columns = new_results_df['predicted'])\n",
    "    \n",
    "new_confusion_matrix"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
