{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab4b515b",
   "metadata": {},
   "source": [
    "# Imports, functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9de958e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- IMPORTS --\n",
    "\n",
    "import scipy.io\n",
    "from pyedflib import highlevel\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from itertools import groupby\n",
    "import csv\n",
    "import pickle\n",
    "from scipy.signal import butter, sosfilt, sosfiltfilt, sosfreqz\n",
    "from scipy.signal import freqz, iirnotch, filtfilt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "import random\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy import signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f900d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- ENVIRONMENT VARIABLES --\n",
    "\n",
    "sample_rate = sampling_rate = 256\n",
    "sec = 10\n",
    "len_window = sample_rate*sec\n",
    "overlap = 5\n",
    "threshold = 2*sample_rate\n",
    "sample_rate_downsample = int(0.1*sample_rate)\n",
    "len_window_downsample = sample_rate_downsample*sec\n",
    "\n",
    "# Load annotation file\n",
    "annt = scipy.io.loadmat('../raw_data/annotations_2017.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24bcfb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "## -- PREPROCESSING FUNCTIONS --\n",
    "\n",
    "# Highpass filter\n",
    "def highpass_filter(signals, sampling_rate, hp_frequency = 0.1):\n",
    "    sos = butter(N = 3, Wn = hp_frequency, btype=\"highpass\",fs=sampling_rate, output=\"sos\")\n",
    "    filter_hp = sosfiltfilt(sos, signals)\n",
    "    return filter_hp\n",
    "\n",
    "# Powerline filter\n",
    "def notch_filter(signals, sampling_rate, notch_frequency = 50, quality_factor = 30):\n",
    "    w0 = notch_frequency/(sampling_rate/2)\n",
    "    b_notch, a_notch = iirnotch(w0, quality_factor)\n",
    "    filter_notch = filtfilt(b_notch, a_notch, signals, axis = -1)\n",
    "    return filter_notch\n",
    "\n",
    "# Create our own scaler\n",
    "class CustomTranformer(TransformerMixin, BaseEstimator): \n",
    "    # BaseEstimator generates the get_params() and set_params() methods that all Pipelines require\n",
    "    # TransformerMixin creates the fit_transform() method from fit() and transform()\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        self.means = X.mean()\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        norm_features = X - self.means\n",
    "        return norm_features\n",
    "\n",
    "# Combination of all filters and Scaler\n",
    "def filter_signals(signals, sampling_rate, scaler, hp_frequency = 0.1, notch_frequency = 50, quality_factor = 30):\n",
    "    filter_hp = highpass_filter(signals, sampling_rate)\n",
    "    filter_notch = notch_filter(filter_hp, sampling_rate, notch_frequency, quality_factor)\n",
    "    final_signal = scaler.fit_transform(filter_notch)\n",
    "    return final_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9294b525",
   "metadata": {},
   "outputs": [],
   "source": [
    "## -- LABEL FUNCTIONS --\n",
    "\n",
    "# Format the EEG \n",
    "def eeg_formated(signals, names_ele):\n",
    "    data_signals = signals.T # transpose the signals from datapoints\n",
    "    data_signals = pd.DataFrame(data_signals) # create a pandas dataframe\n",
    "    \n",
    "    data_signals.columns = names_ele # rename columns\n",
    "    \n",
    "    return data_signals\n",
    "\n",
    "# Format the annotations\n",
    "def diagnosis(n):\n",
    "    patient_A=annt[\"annotat_new\"][0][n-1][0]\n",
    "    patient_B=annt[\"annotat_new\"][0][n-1][1]\n",
    "    patient_C=annt[\"annotat_new\"][0][n-1][2]\n",
    "    \n",
    "    #converting seconds to datapoints\n",
    "\n",
    "    patient_A=patient_A.tolist()\n",
    "    patient_B=patient_B.tolist()\n",
    "    patient_C=patient_C.tolist()\n",
    "    \n",
    "    patient_A_dtp=[]\n",
    "    patient_B_dtp=[]\n",
    "    patient_C_dtp=[]  \n",
    "    for elem in patient_A:\n",
    "        for i in range(sampling_rate):\n",
    "            patient_A_dtp.append(elem) \n",
    "    for elem in patient_B:\n",
    "        for i in range(sampling_rate):\n",
    "            patient_B_dtp.append(elem)\n",
    "        \n",
    "    for elem in patient_C:\n",
    "        for i in range(sampling_rate):\n",
    "            patient_C_dtp.append(elem)\n",
    "            \n",
    "    target_=pd.DataFrame({\"Diagnosis A\":patient_A_dtp,\"Diagnosis B\":patient_B_dtp,\"Diagnosis C\":patient_C_dtp})\n",
    "    \n",
    "    return target_  \n",
    "\n",
    "# Create target variables when seizures lasts at least 10\n",
    "def is_seizure(df):\n",
    "    \n",
    "    threshold = sampling_rate*10\n",
    "    \n",
    "    df['is_seizure_A'] = df[\"Diagnosis A\"].groupby((df[\"Diagnosis A\"] != df[\"Diagnosis A\"].shift()).cumsum()).transform('size') * df[\"Diagnosis A\"]\n",
    "    df['is_seizure_A'] = (df['is_seizure_A'] > threshold).astype(int)\n",
    "    \n",
    "    df['is_seizure_B'] = df[\"Diagnosis B\"].groupby((df[\"Diagnosis B\"] != df[\"Diagnosis B\"].shift()).cumsum()).transform('size') * df[\"Diagnosis B\"]\n",
    "    df['is_seizure_B'] = (df['is_seizure_B'] > threshold).astype(int)\n",
    "    \n",
    "    df['is_seizure_C'] = df[\"Diagnosis C\"].groupby((df[\"Diagnosis C\"] != df[\"Diagnosis C\"].shift()).cumsum()).transform('size') * df[\"Diagnosis C\"]\n",
    "    df['is_seizure_C'] = (df['is_seizure_C'] > threshold).astype(int)\n",
    "    \n",
    "    return df \n",
    "\n",
    "# Create final target\n",
    "def create_target(df):\n",
    "    df['is_seizure_target'] = np.where(df['is_seizure_A'] + df['is_seizure_B'] + df['is_seizure_C'] >= 2, 1, 0)\n",
    "    return df\n",
    "\n",
    "# Remove useless\n",
    "def remove_useless_columns(df):\n",
    "    df.drop(columns=['Diagnosis A', 'Diagnosis B', 'Diagnosis C', 'is_seizure_A', 'is_seizure_B', 'is_seizure_C', 'ECG EKG', 'Resp Effort'], inplace=True)\n",
    "    return df\n",
    "\n",
    "# Final function to label\n",
    "def label_data(path_raw_data, signals_preprocessed, n):\n",
    "    \n",
    "    signals, signal_headers, header = highlevel.read_edf(path_raw_data)\n",
    "    \n",
    "    names_ele = [signal_headers[iele]['label'] for iele in range(signals.shape[0])] # extract electrode names\n",
    "    \n",
    "    eeg_patient = eeg_formated(signals_preprocessed, names_ele) # format the ECG\n",
    "    eeg_patient.rename(columns={'ECG EKG-REF':'ECG EKG', 'Resp Effort-REF':'Resp Effort'}, inplace=True)\n",
    "    \n",
    "    diagnosis_patient = diagnosis(n) # format the diagnosis\n",
    "    \n",
    "    data_patient = pd.merge(left=eeg_patient, right=diagnosis_patient, how='left', left_index=True, right_index=True) # merge ecg and diagnosis\n",
    "    \n",
    "    is_seizure(data_patient)\n",
    "    create_target(data_patient)\n",
    "    remove_useless_columns(data_patient)\n",
    "    \n",
    "    return data_patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb71dc91",
   "metadata": {},
   "outputs": [],
   "source": [
    "## -- FEATURE ENGINEERING --\n",
    "\n",
    "def flatten(window_df):\n",
    "    if len(np.unique(window_df.iloc[:,-1])) == 1:\n",
    "        target = window_df.iloc[0,-1]\n",
    "    elif np.unique(window_df.iloc[:,-1],return_counts=True)[1][1] >= threshold:\n",
    "        target = 1\n",
    "    else:\n",
    "        target = 0\n",
    "    t_df = window_df.drop(columns = \"target\").transpose()\n",
    "    flatten = pd.DataFrame(np.array(t_df).reshape(1,t_df.shape[0]*t_df.shape[1]))\n",
    "    flatten[\"Target\"] = target\n",
    "    return flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d80e8071",
   "metadata": {},
   "outputs": [],
   "source": [
    "## -- MAIN FUNCTIONS --\n",
    "\n",
    "def preprocess_and_label(path_raw_data, scaler, patient_number, Fournier=False):\n",
    "    \n",
    "    # Load raw data\n",
    "    signals, signal_headers, header = highlevel.read_edf(path_raw_data)\n",
    "    \n",
    "    # Preprocess data \n",
    "    signals_preprocessed = filter_signals(signals, sampling_rate, scaler, hp_frequency = 0.1, notch_frequency = 50, quality_factor = 30)\n",
    "    \n",
    "    if Fournier == True:\n",
    "        signals_preprocessed = pd.DataFrame(np.array([abs(rfft(signals_preprocessed[i])) for i in range(len(signals_preprocessed))]))\n",
    "        \n",
    "    # Label data\n",
    "    df = label_data(path_raw_data, signals_preprocessed, patient_number)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def downsampling(df):\n",
    "    df_downsample = pd.DataFrame()\n",
    "    all_df = pd.DataFrame()\n",
    "    target_col = df.iloc[:,-1]\n",
    "    num = int(0.1*sample_rate)\n",
    "    t = 256\n",
    "    for i, column in enumerate(df.columns[:-1]):\n",
    "        df_downsample = pd.DataFrame()\n",
    "        for j in range(0,len(df)-sample_rate,sample_rate):\n",
    "            x = np.array(df.iloc[j:j+sample_rate,i])\n",
    "            x_resampled = pd.DataFrame(signal.resample(x, num), index=range(int(j/10),int(j/10)+num))\n",
    "            df_downsample= pd.concat([df_downsample,x_resampled])\n",
    "        all_df[column] = np.array(df_downsample).reshape(1,-1)[0]\n",
    "    target = []\n",
    "    for t in range(0,len(target_col)-256,sample_rate):\n",
    "        for n in range(num):\n",
    "            target.append(target_col[t])\n",
    "    all_df[\"target\"] = target\n",
    "    return all_df\n",
    "\n",
    "def flatten_dataframe(df):\n",
    "    data = np.array([flatten(df.iloc[i:i+len_window_downsample]) for i in range(0,len(df)-len_window_downsample, overlap*sample_rate_downsample)])\n",
    "    r=data.shape[0]\n",
    "    c=data.shape[2]\n",
    "    data = pd.DataFrame(data.reshape(r,c))\n",
    "    return data\n",
    "\n",
    "def concat_dataframes(dictionnary_of_dataframes):\n",
    "    df = pd.concat([dictionnary_of_dataframes[i] for i in dictionnary_of_dataframes.keys()])\n",
    "    return df\n",
    "\n",
    "def create_x_and_y(df):\n",
    "    X = df.iloc[:,:-1]\n",
    "    y = df.iloc[:,-1]\n",
    "    return X,y\n",
    "\n",
    "def oversampling(X, y): \n",
    "    sm = SMOTE(sampling_strategy='minority', random_state=7)\n",
    "    X, y = sm.fit_resample(X, y)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72adac94",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a2c698c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"../data_modeling/df_train.csv\", index_col=[0])\n",
    "df_test = pd.read_csv(\"../data_modeling/df_test.csv\", index_col=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7d739c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = create_x_and_y(df_train)\n",
    "X_test, y_test = create_x_and_y(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8caa07d5",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9514fb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "751d7d02",
   "metadata": {},
   "source": [
    "## Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ac82e2b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1f0e5b9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999810530703499"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train accuracy \n",
    "y_pred_train = model.predict(X_train)\n",
    "\n",
    "train_score = accuracy_score(y_train, y_pred_train)\n",
    "train_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a8a3e5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model and export it\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f86151b",
   "metadata": {},
   "source": [
    "## Test on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a8e70e15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8927939876215738"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test accuracy\n",
    "y_pred_test = model.predict(X_test)\n",
    "\n",
    "test_score = accuracy_score(y_test, y_pred_test)\n",
    "test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fa7ffbf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>predicted</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>20163</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>2392</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "predicted    0.0  1.0\n",
       "actual               \n",
       "0.0        20163   33\n",
       "1.0         2392   32"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confusion matrix\n",
    "test_results_df = pd.DataFrame({\"actual\": y_test,\n",
    "                           \"predicted\": y_pred_test})\n",
    "    \n",
    "test_confusion_matrix = pd.crosstab(index= test_results_df['actual'],\n",
    "                               columns = test_results_df['predicted'])\n",
    "    \n",
    "test_confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbcb3057",
   "metadata": {},
   "source": [
    "## Test on new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f4e90cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess and label new data\n",
    "path_raw_new_data = \"../raw_data/eeg5.edf\"\n",
    "df_new = preprocess_and_label(path_raw_new_data, CustomTranformer(), 5, Fournier=False)\n",
    "\n",
    "# Downsampling new data\n",
    "df_new_downsample = downsampling(df_new)\n",
    "\n",
    "# Flatten new data\n",
    "df_new_downsample_flat = flatten_dataframe(df_new_downsample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "698d4111",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/florencetersier/.pyenv/versions/3.10.6/envs/SeizurePredict/lib/python3.10/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.17232375979112272"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accuracy\n",
    "y_true = df_new_downsample_flat.iloc[:,-1]\n",
    "y_pred = model.predict(df_new_downsample_flat.iloc[:,:-1])\n",
    "\n",
    "new_score = accuracy_score(y_true, y_pred)\n",
    "new_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3c8188f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>predicted</th>\n",
       "      <th>0.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>634</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "predicted  0.0\n",
       "actual        \n",
       "0.0        132\n",
       "1.0        634"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confusion matrix\n",
    "new_results_df = pd.DataFrame({\"actual\": y_true,\n",
    "                           \"predicted\": y_pred})\n",
    "    \n",
    "new_confusion_matrix = pd.crosstab(index= new_results_df['actual'],\n",
    "                               columns = new_results_df['predicted'])\n",
    "    \n",
    "new_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30ac81d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
