{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b21bc5bb",
   "metadata": {},
   "source": [
    "Goal: apply a DL RNN model on different dataset\n",
    "- Preprocess with MinMaxScaler\n",
    "- Preprocess with CustomerTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aff0c1a",
   "metadata": {},
   "source": [
    "# Imports, variables, functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43f6322e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "from pyedflib import highlevel\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from itertools import groupby\n",
    "import csv\n",
    "import pickle\n",
    "from scipy.signal import butter, sosfilt, sosfiltfilt, sosfreqz\n",
    "from scipy.signal import freqz, iirnotch, filtfilt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "import random\n",
    "from sklearn.model_selection import cross_validate\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.fftpack import rfft\n",
    "from sklearn.metrics import accuracy_score\n",
    "import tensorflow as ts\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from plot_keras_history import plot_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f2e6638",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_rate = sampling_rate = 256\n",
    "sec = 10\n",
    "len_window = sample_rate*sec\n",
    "overlap = 5\n",
    "\n",
    "# Load annotation file\n",
    "annt = scipy.io.loadmat('../raw_data/annotations_2017.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a43d318",
   "metadata": {},
   "outputs": [],
   "source": [
    "## -- PREPROCESSING FUNCTIONS --\n",
    "\n",
    "# Highpass filter\n",
    "def highpass_filter(signals, sampling_rate, hp_frequency = 0.1):\n",
    "    sos = butter(N = 3, Wn = hp_frequency, btype=\"highpass\",fs=sampling_rate, output=\"sos\")\n",
    "    filter_hp = sosfiltfilt(sos, signals)\n",
    "    return filter_hp\n",
    "\n",
    "# Powerline filter\n",
    "def notch_filter(signals, sampling_rate, notch_frequency = 50, quality_factor = 30):\n",
    "    w0 = notch_frequency/(sampling_rate/2)\n",
    "    b_notch, a_notch = iirnotch(w0, quality_factor)\n",
    "    filter_notch = filtfilt(b_notch, a_notch, signals, axis = -1)\n",
    "    return filter_notch\n",
    "\n",
    "# Create our own scaler\n",
    "class CustomTranformer(TransformerMixin, BaseEstimator): \n",
    "    # BaseEstimator generates the get_params() and set_params() methods that all Pipelines require\n",
    "    # TransformerMixin creates the fit_transform() method from fit() and transform()\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        self.means = X.mean()\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        norm_features = X - self.means\n",
    "        return norm_features\n",
    "\n",
    "# Combination of all filters and Scaler\n",
    "def filter_signals(signals, sampling_rate, scaler, hp_frequency = 0.1, notch_frequency = 50, quality_factor = 30):\n",
    "    filter_hp = highpass_filter(signals, sampling_rate)\n",
    "    filter_notch = notch_filter(signals, sampling_rate, notch_frequency, quality_factor)\n",
    "    final_signal = scaler.fit_transform(filter_notch)\n",
    "    return final_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7961b948",
   "metadata": {},
   "outputs": [],
   "source": [
    "## -- LABEL FUNCTIONS --\n",
    "\n",
    "# Format the EEG \n",
    "def eeg_formated(signals, names_ele):\n",
    "    data_signals = signals.T # transpose the signals from datapoints\n",
    "    data_signals = pd.DataFrame(data_signals) # create a pandas dataframe\n",
    "    \n",
    "    data_signals.columns = names_ele # rename columns\n",
    "    \n",
    "    return data_signals\n",
    "\n",
    "# Format the annotations\n",
    "def diagnosis(n):\n",
    "    patient_A=annt[\"annotat_new\"][0][n-1][0]\n",
    "    patient_B=annt[\"annotat_new\"][0][n-1][1]\n",
    "    patient_C=annt[\"annotat_new\"][0][n-1][2]\n",
    "    \n",
    "    #converting seconds to datapoints\n",
    "\n",
    "    patient_A=patient_A.tolist()\n",
    "    patient_B=patient_B.tolist()\n",
    "    patient_C=patient_C.tolist()\n",
    "    \n",
    "    patient_A_dtp=[]\n",
    "    patient_B_dtp=[]\n",
    "    patient_C_dtp=[]  \n",
    "    for elem in patient_A:\n",
    "        for i in range(sampling_rate):\n",
    "            patient_A_dtp.append(elem) \n",
    "    for elem in patient_B:\n",
    "        for i in range(sampling_rate):\n",
    "            patient_B_dtp.append(elem)\n",
    "        \n",
    "    for elem in patient_C:\n",
    "        for i in range(sampling_rate):\n",
    "            patient_C_dtp.append(elem)\n",
    "            \n",
    "    target_=pd.DataFrame({\"Diagnosis A\":patient_A_dtp,\"Diagnosis B\":patient_B_dtp,\"Diagnosis C\":patient_C_dtp})\n",
    "    \n",
    "    return target_  \n",
    "\n",
    "# Add a time column with the seconds\n",
    "def add_time(df):\n",
    "    list_time=[]\n",
    "    for i in range(len(df)):\n",
    "        list_time.append(i//sampling_rate)\n",
    "    df[\"time\"]=list_time\n",
    "    return df\n",
    "\n",
    "# Create target variables when seizures lasts at least 10\n",
    "def is_seizure(df):\n",
    "    \n",
    "    threshold = sampling_rate*10\n",
    "    \n",
    "    df['is_seizure_A'] = df[\"Diagnosis A\"].groupby((df[\"Diagnosis A\"] != df[\"Diagnosis A\"].shift()).cumsum()).transform('size') * df[\"Diagnosis A\"]\n",
    "    df['is_seizure_A'] = (df['is_seizure_A'] > threshold).astype(int)\n",
    "    \n",
    "    df['is_seizure_B'] = df[\"Diagnosis B\"].groupby((df[\"Diagnosis B\"] != df[\"Diagnosis B\"].shift()).cumsum()).transform('size') * df[\"Diagnosis B\"]\n",
    "    df['is_seizure_B'] = (df['is_seizure_B'] > threshold).astype(int)\n",
    "    \n",
    "    df['is_seizure_C'] = df[\"Diagnosis C\"].groupby((df[\"Diagnosis C\"] != df[\"Diagnosis C\"].shift()).cumsum()).transform('size') * df[\"Diagnosis C\"]\n",
    "    df['is_seizure_C'] = (df['is_seizure_C'] > threshold).astype(int)\n",
    "    \n",
    "    return df \n",
    "\n",
    "# Create final target\n",
    "def create_target(df):\n",
    "    df['is_seizure_target'] = np.where(df['is_seizure_A'] + df['is_seizure_B'] + df['is_seizure_C'] >= 2, 1, 0)\n",
    "    return df\n",
    "\n",
    "# Remove useless\n",
    "def remove_useless_columns(df):\n",
    "    df.drop(columns=['Diagnosis A', 'Diagnosis B', 'Diagnosis C', 'is_seizure_A', 'is_seizure_B', 'is_seizure_C', 'ECG EKG', 'Resp Effort', 'time'], inplace=True)\n",
    "    return df\n",
    "\n",
    "# Final function to label\n",
    "def label_data(path_raw_data, signals_preprocessed, n):\n",
    "    \n",
    "    signals, signal_headers, header = highlevel.read_edf(path_raw_data)\n",
    "    \n",
    "    names_ele = [signal_headers[iele]['label'] for iele in range(signals.shape[0])] # extract electrode names\n",
    "    \n",
    "    eeg_patient = eeg_formated(signals_preprocessed, names_ele) # format the ECG\n",
    "    eeg_patient.rename(columns={'ECG EKG-REF':'ECG EKG', 'Resp Effort-REF':'Resp Effort'}, inplace=True)\n",
    "    diagnosis_patient = diagnosis(n) # format the diagnosis\n",
    "    \n",
    "    data_patient = pd.merge(left=eeg_patient, right=diagnosis_patient, how='left', left_index=True, right_index=True) # merge ecg and diagnosis\n",
    "    \n",
    "    add_time(data_patient)\n",
    "    is_seizure(data_patient)\n",
    "    create_target(data_patient)\n",
    "    remove_useless_columns(data_patient)\n",
    "    \n",
    "    return data_patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30623872",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_input(df):\n",
    "    data = np.array((df.iloc[i:i+len_window+1]) for i in range(0,len(df)-len_window, overlap*sample_rate))\n",
    "    r=data.shape[0]\n",
    "    c=data.shape[1]\n",
    "    data = pd.DataFrame(data.reshape(r,c))\n",
    "    \n",
    "    X = data.iloc[:,:-1]\n",
    "    y = data.iloc[:,-1]\n",
    "    return X,y\n",
    "\n",
    "def oversampling(X, y): \n",
    "    sm = SMOTE(sampling_strategy='minority', random_state=7)\n",
    "    X, y = sm.fit_resample(X, y)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc3e4f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_pipeline(path_raw_data, scaler, patient_number, Fournier=False):\n",
    "    \n",
    "    # Load raw data\n",
    "    signals, signal_headers, header = highlevel.read_edf(path_raw_data)\n",
    "    \n",
    "    # Preprocess data \n",
    "    signals_preprocessed = filter_signals(signals, sampling_rate, scaler, hp_frequency = 0.1, notch_frequency = 50, quality_factor = 30)\n",
    "    \n",
    "    if Fournier == True:\n",
    "        signals_preprocessed = pd.DataFrame(np.array([abs(rfft(signals_preprocessed[i])) for i in range(len(signals_preprocessed))]))\n",
    "        \n",
    "    # Label data\n",
    "    df = label_data(path_raw_data, signals_preprocessed, patient_number)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9398bda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = model_pipeline(\"../raw_data/eeg5.edf\",  MinMaxScaler(), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "255db3b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EEG Fp1-Ref</th>\n",
       "      <th>EEG Fp2-Ref</th>\n",
       "      <th>EEG F7-Ref</th>\n",
       "      <th>EEG F3-Ref</th>\n",
       "      <th>EEG Fz-Ref</th>\n",
       "      <th>EEG F4-Ref</th>\n",
       "      <th>EEG F8-Ref</th>\n",
       "      <th>EEG T3-Ref</th>\n",
       "      <th>EEG C3-Ref</th>\n",
       "      <th>EEG Cz-Ref</th>\n",
       "      <th>EEG C4-Ref</th>\n",
       "      <th>EEG T4-Ref</th>\n",
       "      <th>EEG T5-Ref</th>\n",
       "      <th>EEG P3-Ref</th>\n",
       "      <th>EEG Pz-Ref</th>\n",
       "      <th>EEG P4-Ref</th>\n",
       "      <th>EEG T6-Ref</th>\n",
       "      <th>EEG O1-Ref</th>\n",
       "      <th>EEG O2-Ref</th>\n",
       "      <th>is_seizure_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.353494</td>\n",
       "      <td>0.793573</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.701917</td>\n",
       "      <td>0.393511</td>\n",
       "      <td>0.183450</td>\n",
       "      <td>0.846558</td>\n",
       "      <td>0.579165</td>\n",
       "      <td>0.018523</td>\n",
       "      <td>0.627815</td>\n",
       "      <td>0.863314</td>\n",
       "      <td>0.909277</td>\n",
       "      <td>0.289584</td>\n",
       "      <td>0.190606</td>\n",
       "      <td>0.209212</td>\n",
       "      <td>0.769056</td>\n",
       "      <td>0.731333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.179405</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.336246</td>\n",
       "      <td>0.862974</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.638187</td>\n",
       "      <td>0.376305</td>\n",
       "      <td>0.179248</td>\n",
       "      <td>0.838919</td>\n",
       "      <td>0.609300</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.605302</td>\n",
       "      <td>0.854773</td>\n",
       "      <td>0.920654</td>\n",
       "      <td>0.291398</td>\n",
       "      <td>0.199013</td>\n",
       "      <td>0.214853</td>\n",
       "      <td>0.768280</td>\n",
       "      <td>0.729059</td>\n",
       "      <td>0.017021</td>\n",
       "      <td>0.195751</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.268712</td>\n",
       "      <td>0.919813</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.511203</td>\n",
       "      <td>0.356371</td>\n",
       "      <td>0.224427</td>\n",
       "      <td>0.850186</td>\n",
       "      <td>0.618169</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.601201</td>\n",
       "      <td>0.863473</td>\n",
       "      <td>0.937578</td>\n",
       "      <td>0.305050</td>\n",
       "      <td>0.191920</td>\n",
       "      <td>0.219181</td>\n",
       "      <td>0.799121</td>\n",
       "      <td>0.757659</td>\n",
       "      <td>0.045152</td>\n",
       "      <td>0.243526</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.347118</td>\n",
       "      <td>0.805896</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.618322</td>\n",
       "      <td>0.364362</td>\n",
       "      <td>0.234248</td>\n",
       "      <td>0.866393</td>\n",
       "      <td>0.616341</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.607192</td>\n",
       "      <td>0.876478</td>\n",
       "      <td>0.956812</td>\n",
       "      <td>0.308363</td>\n",
       "      <td>0.211140</td>\n",
       "      <td>0.236517</td>\n",
       "      <td>0.800898</td>\n",
       "      <td>0.770108</td>\n",
       "      <td>0.051896</td>\n",
       "      <td>0.248591</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.425620</td>\n",
       "      <td>0.772917</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.615228</td>\n",
       "      <td>0.351910</td>\n",
       "      <td>0.214835</td>\n",
       "      <td>0.839804</td>\n",
       "      <td>0.504690</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.602062</td>\n",
       "      <td>0.856330</td>\n",
       "      <td>0.955345</td>\n",
       "      <td>0.270725</td>\n",
       "      <td>0.206211</td>\n",
       "      <td>0.235480</td>\n",
       "      <td>0.804234</td>\n",
       "      <td>0.765600</td>\n",
       "      <td>0.037186</td>\n",
       "      <td>0.232421</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983291</th>\n",
       "      <td>0.358651</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.446580</td>\n",
       "      <td>0.350410</td>\n",
       "      <td>0.431132</td>\n",
       "      <td>0.438771</td>\n",
       "      <td>0.431005</td>\n",
       "      <td>0.601553</td>\n",
       "      <td>0.432301</td>\n",
       "      <td>0.466851</td>\n",
       "      <td>0.486067</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.440335</td>\n",
       "      <td>0.429410</td>\n",
       "      <td>0.481188</td>\n",
       "      <td>0.497280</td>\n",
       "      <td>0.360721</td>\n",
       "      <td>0.479454</td>\n",
       "      <td>0.489994</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983292</th>\n",
       "      <td>0.027400</td>\n",
       "      <td>0.011211</td>\n",
       "      <td>0.029130</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017762</td>\n",
       "      <td>0.040012</td>\n",
       "      <td>0.040446</td>\n",
       "      <td>0.011096</td>\n",
       "      <td>0.022597</td>\n",
       "      <td>0.031731</td>\n",
       "      <td>0.056863</td>\n",
       "      <td>0.153933</td>\n",
       "      <td>0.036740</td>\n",
       "      <td>0.039975</td>\n",
       "      <td>0.053607</td>\n",
       "      <td>0.071216</td>\n",
       "      <td>0.108301</td>\n",
       "      <td>0.072665</td>\n",
       "      <td>0.062631</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983293</th>\n",
       "      <td>0.040683</td>\n",
       "      <td>0.080363</td>\n",
       "      <td>0.029821</td>\n",
       "      <td>0.027907</td>\n",
       "      <td>0.026126</td>\n",
       "      <td>0.036374</td>\n",
       "      <td>0.037631</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028419</td>\n",
       "      <td>0.028432</td>\n",
       "      <td>0.038594</td>\n",
       "      <td>0.019143</td>\n",
       "      <td>0.034508</td>\n",
       "      <td>0.037605</td>\n",
       "      <td>0.037596</td>\n",
       "      <td>0.044365</td>\n",
       "      <td>0.081376</td>\n",
       "      <td>0.047479</td>\n",
       "      <td>0.040991</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983294</th>\n",
       "      <td>0.966625</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.959231</td>\n",
       "      <td>0.976907</td>\n",
       "      <td>0.964426</td>\n",
       "      <td>0.956003</td>\n",
       "      <td>0.956450</td>\n",
       "      <td>0.953622</td>\n",
       "      <td>0.962633</td>\n",
       "      <td>0.956752</td>\n",
       "      <td>0.946422</td>\n",
       "      <td>0.872591</td>\n",
       "      <td>0.957035</td>\n",
       "      <td>0.956739</td>\n",
       "      <td>0.947944</td>\n",
       "      <td>0.940503</td>\n",
       "      <td>0.937985</td>\n",
       "      <td>0.941369</td>\n",
       "      <td>0.944088</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983295</th>\n",
       "      <td>0.112307</td>\n",
       "      <td>0.088292</td>\n",
       "      <td>0.121311</td>\n",
       "      <td>0.149366</td>\n",
       "      <td>0.135126</td>\n",
       "      <td>0.105155</td>\n",
       "      <td>0.103543</td>\n",
       "      <td>0.166518</td>\n",
       "      <td>0.128550</td>\n",
       "      <td>0.120323</td>\n",
       "      <td>0.087845</td>\n",
       "      <td>0.019465</td>\n",
       "      <td>0.109912</td>\n",
       "      <td>0.103993</td>\n",
       "      <td>0.091743</td>\n",
       "      <td>0.069328</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.064998</td>\n",
       "      <td>0.080328</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>983296 rows Ã— 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        EEG Fp1-Ref  EEG Fp2-Ref  EEG F7-Ref  EEG F3-Ref  EEG Fz-Ref  \\\n",
       "0          0.353494     0.793573    1.000000    0.701917    0.393511   \n",
       "1          0.336246     0.862974    1.000000    0.638187    0.376305   \n",
       "2          0.268712     0.919813    1.000000    0.511203    0.356371   \n",
       "3          0.347118     0.805896    1.000000    0.618322    0.364362   \n",
       "4          0.425620     0.772917    1.000000    0.615228    0.351910   \n",
       "...             ...          ...         ...         ...         ...   \n",
       "983291     0.358651     0.000000    0.446580    0.350410    0.431132   \n",
       "983292     0.027400     0.011211    0.029130    0.000000    0.017762   \n",
       "983293     0.040683     0.080363    0.029821    0.027907    0.026126   \n",
       "983294     0.966625     1.000000    0.959231    0.976907    0.964426   \n",
       "983295     0.112307     0.088292    0.121311    0.149366    0.135126   \n",
       "\n",
       "        EEG F4-Ref  EEG F8-Ref  EEG T3-Ref  EEG C3-Ref  EEG Cz-Ref  \\\n",
       "0         0.183450    0.846558    0.579165    0.018523    0.627815   \n",
       "1         0.179248    0.838919    0.609300    0.000000    0.605302   \n",
       "2         0.224427    0.850186    0.618169    0.000000    0.601201   \n",
       "3         0.234248    0.866393    0.616341    0.000000    0.607192   \n",
       "4         0.214835    0.839804    0.504690    0.000000    0.602062   \n",
       "...            ...         ...         ...         ...         ...   \n",
       "983291    0.438771    0.431005    0.601553    0.432301    0.466851   \n",
       "983292    0.040012    0.040446    0.011096    0.022597    0.031731   \n",
       "983293    0.036374    0.037631    0.000000    0.028419    0.028432   \n",
       "983294    0.956003    0.956450    0.953622    0.962633    0.956752   \n",
       "983295    0.105155    0.103543    0.166518    0.128550    0.120323   \n",
       "\n",
       "        EEG C4-Ref  EEG T4-Ref  EEG T5-Ref  EEG P3-Ref  EEG Pz-Ref  \\\n",
       "0         0.863314    0.909277    0.289584    0.190606    0.209212   \n",
       "1         0.854773    0.920654    0.291398    0.199013    0.214853   \n",
       "2         0.863473    0.937578    0.305050    0.191920    0.219181   \n",
       "3         0.876478    0.956812    0.308363    0.211140    0.236517   \n",
       "4         0.856330    0.955345    0.270725    0.206211    0.235480   \n",
       "...            ...         ...         ...         ...         ...   \n",
       "983291    0.486067    1.000000    0.440335    0.429410    0.481188   \n",
       "983292    0.056863    0.153933    0.036740    0.039975    0.053607   \n",
       "983293    0.038594    0.019143    0.034508    0.037605    0.037596   \n",
       "983294    0.946422    0.872591    0.957035    0.956739    0.947944   \n",
       "983295    0.087845    0.019465    0.109912    0.103993    0.091743   \n",
       "\n",
       "        EEG P4-Ref  EEG T6-Ref  EEG O1-Ref  EEG O2-Ref  is_seizure_target  \n",
       "0         0.769056    0.731333    0.000000    0.179405                  1  \n",
       "1         0.768280    0.729059    0.017021    0.195751                  1  \n",
       "2         0.799121    0.757659    0.045152    0.243526                  1  \n",
       "3         0.800898    0.770108    0.051896    0.248591                  1  \n",
       "4         0.804234    0.765600    0.037186    0.232421                  1  \n",
       "...            ...         ...         ...         ...                ...  \n",
       "983291    0.497280    0.360721    0.479454    0.489994                  0  \n",
       "983292    0.071216    0.108301    0.072665    0.062631                  0  \n",
       "983293    0.044365    0.081376    0.047479    0.040991                  0  \n",
       "983294    0.940503    0.937985    0.941369    0.944088                  0  \n",
       "983295    0.069328    0.000000    0.064998    0.080328                  0  \n",
       "\n",
       "[983296 rows x 20 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c30d50c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def redefine_window_target(window_df):\n",
    "    if len(np.unique(window_df.iloc[:,-1])) == 1:\n",
    "        target = window_df.iloc[0,-1]\n",
    "    elif np.unique(window_df.iloc[:,-1],return_counts=True)[1][1] >= 2*256:\n",
    "        target = 1\n",
    "    else:\n",
    "        target = 0\n",
    "    t_df = window_df.drop(columns = \"is_seizure_target\")\n",
    "    window = pd.DataFrame(np.array(t_df))\n",
    "    window[\"Target\"] = target\n",
    "    return window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3da8cf4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(767, 2561, 20)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.array([redefine_window_target(df.iloc[i:i+len_window+1]) for i in range(0,len(df)-len_window, overlap*sample_rate)])\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d74e308",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[3.53494062e-01, 7.93573255e-01, 1.00000000e+00, ...,\n",
       "         0.00000000e+00, 1.79405397e-01, 1.00000000e+00],\n",
       "        [3.36246299e-01, 8.62974373e-01, 1.00000000e+00, ...,\n",
       "         1.70209856e-02, 1.95750725e-01, 1.00000000e+00],\n",
       "        [2.68711671e-01, 9.19812579e-01, 1.00000000e+00, ...,\n",
       "         4.51515001e-02, 2.43526078e-01, 1.00000000e+00],\n",
       "        ...,\n",
       "        [8.75534928e-02, 1.66695863e-01, 9.94047856e-02, ...,\n",
       "         7.10290788e-01, 1.63347397e-01, 1.00000000e+00],\n",
       "        [6.18149653e-02, 1.83765118e-01, 9.64423588e-02, ...,\n",
       "         8.66426084e-01, 1.88153130e-01, 1.00000000e+00],\n",
       "        [5.43778494e-02, 1.70836409e-01, 3.18727842e-02, ...,\n",
       "         8.79038209e-01, 2.35308625e-01, 1.00000000e+00]],\n",
       "\n",
       "       [[8.29088616e-01, 8.30583388e-01, 4.69496251e-01, ...,\n",
       "         2.73895195e-01, 4.87277941e-01, 1.00000000e+00],\n",
       "        [8.40356909e-01, 8.68702377e-01, 4.62443568e-01, ...,\n",
       "         2.53164669e-01, 4.67961170e-01, 1.00000000e+00],\n",
       "        [8.51128389e-01, 9.25711014e-01, 4.62421872e-01, ...,\n",
       "         2.53349911e-01, 4.80779719e-01, 1.00000000e+00],\n",
       "        ...,\n",
       "        [3.50813296e-01, 3.14306479e-01, 4.37533315e-01, ...,\n",
       "         8.85957769e-01, 9.78581546e-01, 1.00000000e+00],\n",
       "        [3.57406549e-01, 3.23895552e-01, 5.03597472e-01, ...,\n",
       "         9.07042658e-01, 9.63351867e-01, 1.00000000e+00],\n",
       "        [2.87340148e-01, 2.61433242e-01, 4.41453712e-01, ...,\n",
       "         7.94058900e-01, 8.40223667e-01, 1.00000000e+00]],\n",
       "\n",
       "       [[5.43778494e-02, 1.70836409e-01, 3.18727842e-02, ...,\n",
       "         8.79038209e-01, 2.35308625e-01, 1.00000000e+00],\n",
       "        [5.86819177e-02, 2.20751207e-01, 0.00000000e+00, ...,\n",
       "         8.66901877e-01, 3.10591222e-01, 1.00000000e+00],\n",
       "        [1.38895641e-01, 3.03251523e-01, 1.98529943e-02, ...,\n",
       "         8.02883978e-01, 3.97904899e-01, 1.00000000e+00],\n",
       "        ...,\n",
       "        [2.16974595e-01, 2.79709582e-01, 5.15013860e-01, ...,\n",
       "         7.92624128e-01, 6.32683675e-01, 1.00000000e+00],\n",
       "        [2.47121059e-01, 2.95757787e-01, 5.26306187e-01, ...,\n",
       "         8.06815262e-01, 6.37317811e-01, 1.00000000e+00],\n",
       "        [2.64918294e-01, 2.92292550e-01, 5.43013040e-01, ...,\n",
       "         8.04972929e-01, 6.48699241e-01, 1.00000000e+00]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[1.50165430e-01, 9.00963742e-02, 2.50929271e-01, ...,\n",
       "         3.15887415e-01, 1.51568116e-01, 1.00000000e+00],\n",
       "        [4.71892691e-01, 3.87330333e-01, 5.78254735e-01, ...,\n",
       "         7.14225219e-01, 3.64602831e-01, 1.00000000e+00],\n",
       "        [8.21147529e-01, 8.20716085e-01, 8.79649389e-01, ...,\n",
       "         9.34479955e-01, 8.19172003e-01, 1.00000000e+00],\n",
       "        ...,\n",
       "        [6.83904495e-01, 5.80544226e-01, 7.31861485e-01, ...,\n",
       "         1.00000000e+00, 8.73573111e-01, 1.00000000e+00],\n",
       "        [7.73965478e-01, 6.86889507e-01, 7.45057593e-01, ...,\n",
       "         1.00000000e+00, 8.81270081e-01, 1.00000000e+00],\n",
       "        [8.16740759e-01, 6.62609289e-01, 7.74357821e-01, ...,\n",
       "         1.00000000e+00, 9.08991428e-01, 1.00000000e+00]],\n",
       "\n",
       "       [[6.10258645e-01, 4.96598773e-01, 7.53920225e-01, ...,\n",
       "         8.29695160e-01, 6.70722527e-01, 1.00000000e+00],\n",
       "        [6.69129331e-01, 6.27887807e-01, 7.77890552e-01, ...,\n",
       "         8.63232871e-01, 7.10388938e-01, 1.00000000e+00],\n",
       "        [6.47286058e-01, 6.44700062e-01, 7.74601761e-01, ...,\n",
       "         8.76941041e-01, 7.07227508e-01, 1.00000000e+00],\n",
       "        ...,\n",
       "        [3.40812603e-01, 0.00000000e+00, 2.71796088e-01, ...,\n",
       "         5.78322363e-01, 4.20220462e-01, 1.00000000e+00],\n",
       "        [2.62093460e-01, 0.00000000e+00, 1.86359241e-01, ...,\n",
       "         5.35777016e-01, 3.51059347e-01, 1.00000000e+00],\n",
       "        [4.29635448e-01, 2.16391074e-01, 1.87171521e-01, ...,\n",
       "         5.52000814e-01, 3.58747134e-01, 1.00000000e+00]],\n",
       "\n",
       "       [[8.16740759e-01, 6.62609289e-01, 7.74357821e-01, ...,\n",
       "         1.00000000e+00, 9.08991428e-01, 1.00000000e+00],\n",
       "        [5.87933288e-01, 8.39913501e-01, 6.83938840e-01, ...,\n",
       "         1.00000000e+00, 8.57520775e-01, 1.00000000e+00],\n",
       "        [6.81550543e-01, 6.83518812e-01, 6.65318378e-01, ...,\n",
       "         1.00000000e+00, 8.09797498e-01, 1.00000000e+00],\n",
       "        ...,\n",
       "        [4.73229768e-01, 6.37814513e-01, 5.02347388e-01, ...,\n",
       "         0.00000000e+00, 6.60527521e-01, 1.00000000e+00],\n",
       "        [5.44469149e-01, 5.48017380e-01, 5.12269455e-01, ...,\n",
       "         2.07564765e-04, 6.93086193e-01, 1.00000000e+00],\n",
       "        [6.51229587e-01, 6.84839772e-01, 6.30927734e-01, ...,\n",
       "         8.91959965e-03, 8.14099352e-01, 1.00000000e+00]]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "973125c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#r=data.shape[0]*data.shape[1]\n",
    "#c=data.shape[2]\n",
    "    \n",
    "#data = pd.DataFrame(data.reshape(r,c))\n",
    "X = data[:,:,:-1]\n",
    "y = data[:,:,-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "998c9dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=y.sum(axis=1)>=2*256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4725d8b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6302ceae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def oversampling(X, y): \n",
    "    sm = SMOTE(sampling_strategy='minority', random_state=7)\n",
    "    X, y = sm.fit_resample(X, y)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b34c9454",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_ind, test_ind = train_test_split(np.arange(767), test_size=0.2)\n",
    "\n",
    "X_train = X[train_ind,:,:]\n",
    "X_test = X[test_ind,:,:]\n",
    "y_train = y[train_ind]\n",
    "y_test = y[test_ind]\n",
    "\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2)\n",
    "    \n",
    "    # Balancing\n",
    "\n",
    "#X_train, y_train = oversampling(X_train, y_train)\n",
    "#y_train.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "724e88a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "        True,  True,  True, False,  True,  True,  True,  True,  True,\n",
       "        True, False,  True, False,  True, False,  True, False,  True,\n",
       "       False,  True,  True,  True, False, False,  True, False, False,\n",
       "        True,  True,  True,  True,  True,  True, False,  True,  True,\n",
       "        True,  True,  True,  True, False,  True,  True,  True,  True,\n",
       "        True,  True, False,  True,  True,  True,  True, False,  True,\n",
       "        True, False, False,  True,  True,  True,  True,  True,  True,\n",
       "        True, False,  True, False,  True,  True,  True,  True,  True,\n",
       "       False,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "        True,  True,  True,  True,  True,  True, False,  True,  True,\n",
       "        True, False,  True, False,  True,  True,  True,  True,  True,\n",
       "        True, False,  True, False,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True, False,  True,  True,  True,  True,\n",
       "        True, False, False,  True,  True, False,  True,  True,  True,\n",
       "        True, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True, False,  True, False,  True,  True,  True, False,  True,\n",
       "        True,  True,  True, False, False,  True,  True,  True,  True,\n",
       "        True,  True, False,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True, False,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True, False,  True,\n",
       "        True,  True,  True, False,  True, False, False, False,  True,\n",
       "        True,  True,  True,  True,  True, False,  True,  True,  True,\n",
       "        True,  True,  True, False,  True, False,  True, False, False,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "        True,  True,  True,  True,  True,  True,  True, False,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True, False,  True,  True,  True, False,  True, False,\n",
       "        True,  True,  True,  True,  True,  True,  True, False,  True,\n",
       "        True, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "       False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True, False,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "       False, False,  True,  True, False,  True,  True, False, False,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "       False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "       False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True, False,  True,\n",
       "        True,  True,  True,  True,  True,  True, False,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True, False,  True,  True,  True,  True,  True, False,  True,\n",
       "        True,  True,  True, False,  True,  True,  True, False,  True,\n",
       "        True,  True,  True,  True,  True,  True, False,  True,  True,\n",
       "        True,  True,  True,  True, False,  True,  True,  True,  True,\n",
       "        True,  True,  True, False, False,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "       False,  True,  True, False,  True,  True, False,  True,  True,\n",
       "       False,  True, False,  True,  True,  True,  True, False,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "       False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True, False,  True,\n",
       "        True,  True,  True, False,  True,  True, False,  True,  True,\n",
       "        True, False,  True, False,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True, False,  True,\n",
       "        True, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "       False,  True,  True, False,  True,  True, False,  True, False,\n",
       "        True,  True,  True,  True,  True,  True,  True, False,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "       False])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dc938780",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(613, 2561, 19)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape #n.reshape((767, 2561, 19))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fb818d59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-02 17:08:16.287062: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:03:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-12-02 17:08:16.287311: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-12-02 17:08:16.287361: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2022-12-02 17:08:16.287402: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2022-12-02 17:08:16.287441: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2022-12-02 17:08:16.287508: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2022-12-02 17:08:16.287552: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2022-12-02 17:08:16.287592: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2022-12-02 17:08:16.287632: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2022-12-02 17:08:16.287666: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-12-02 17:08:16.289231: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f074cdffdc0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.SimpleRNN(units=10, activation='tanh',input_shape=(2561, 19)))\n",
    "model.add(layers.Dense(10, activation=\"relu\"))\n",
    "model.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "# The compilation\n",
    "model.compile(\n",
    "        optimizer='rmsprop',\n",
    "        loss='binary_crossentropy', \n",
    "        metrics=[ts.keras.metrics.Recall(),\"accuracy\"])\n",
    "\n",
    "# The fit\n",
    "model.fit(X_train, y_train,\n",
    "         batch_size=32,\n",
    "         epochs=50, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2699f2a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 106ms/step - loss: 0.4387 - recall: 1.0000 - accuracy: 0.8442\n",
      "0.4387163519859314 1.0 0.8441558480262756\n"
     ]
    }
   ],
   "source": [
    "results_DL =model.evaluate(X_test, y_test)\n",
    "loss=results_DL[0]\n",
    "recall = results_DL[1]\n",
    "accuracy = results_DL[2]\n",
    "print(loss,recall,accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d531db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
