{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b21bc5bb",
   "metadata": {},
   "source": [
    "Goal: apply a DL RNN model on different dataset\n",
    "- Preprocess with MinMaxScaler\n",
    "- Preprocess with CustomerTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aff0c1a",
   "metadata": {},
   "source": [
    "# Imports, variables, functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f6322e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "from pyedflib import highlevel\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from itertools import groupby\n",
    "import csv\n",
    "import pickle\n",
    "from scipy.signal import butter, sosfilt, sosfiltfilt, sosfreqz\n",
    "from scipy.signal import freqz, iirnotch, filtfilt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "import random\n",
    "from sklearn.model_selection import cross_validate\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.fftpack import rfft\n",
    "from sklearn.metrics import accuracy_score\n",
    "import tensorflow as ts\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from plot_keras_history import plot_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2e6638",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_rate = sampling_rate = 256\n",
    "sec = 10\n",
    "len_window = sample_rate*sec\n",
    "overlap = 5\n",
    "\n",
    "# Load annotation file\n",
    "annt = scipy.io.loadmat('../raw_data/annotations_2017.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a43d318",
   "metadata": {},
   "outputs": [],
   "source": [
    "## -- PREPROCESSING FUNCTIONS --\n",
    "\n",
    "# Highpass filter\n",
    "def highpass_filter(signals, sampling_rate, hp_frequency = 0.1):\n",
    "    sos = butter(N = 3, Wn = hp_frequency, btype=\"highpass\",fs=sampling_rate, output=\"sos\")\n",
    "    filter_hp = sosfiltfilt(sos, signals)\n",
    "    return filter_hp\n",
    "\n",
    "# Powerline filter\n",
    "def notch_filter(signals, sampling_rate, notch_frequency = 50, quality_factor = 30):\n",
    "    w0 = notch_frequency/(sampling_rate/2)\n",
    "    b_notch, a_notch = iirnotch(w0, quality_factor)\n",
    "    filter_notch = filtfilt(b_notch, a_notch, signals, axis = -1)\n",
    "    return filter_notch\n",
    "\n",
    "# Create our own scaler\n",
    "class CustomTranformer(TransformerMixin, BaseEstimator): \n",
    "    # BaseEstimator generates the get_params() and set_params() methods that all Pipelines require\n",
    "    # TransformerMixin creates the fit_transform() method from fit() and transform()\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        self.means = X.mean()\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        norm_features = X - self.means\n",
    "        return norm_features\n",
    "\n",
    "# Combination of all filters and Scaler\n",
    "def filter_signals(signals, sampling_rate, scaler, hp_frequency = 0.1, notch_frequency = 50, quality_factor = 30):\n",
    "    filter_hp = highpass_filter(signals, sampling_rate)\n",
    "    filter_notch = notch_filter(filter_hp, sampling_rate, notch_frequency, quality_factor)\n",
    "    final_signal = scaler.fit_transform(filter_notch)\n",
    "    return final_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7961b948",
   "metadata": {},
   "outputs": [],
   "source": [
    "## -- LABEL FUNCTIONS --\n",
    "\n",
    "# Format the EEG \n",
    "def eeg_formated(signals, names_ele):\n",
    "    data_signals = signals.T # transpose the signals from datapoints\n",
    "    data_signals = pd.DataFrame(data_signals) # create a pandas dataframe\n",
    "    \n",
    "    data_signals.columns = names_ele # rename columns\n",
    "    \n",
    "    return data_signals\n",
    "\n",
    "# Format the annotations\n",
    "def diagnosis(n):\n",
    "    patient_A=annt[\"annotat_new\"][0][n-1][0]\n",
    "    patient_B=annt[\"annotat_new\"][0][n-1][1]\n",
    "    patient_C=annt[\"annotat_new\"][0][n-1][2]\n",
    "    \n",
    "    #converting seconds to datapoints\n",
    "\n",
    "    patient_A=patient_A.tolist()\n",
    "    patient_B=patient_B.tolist()\n",
    "    patient_C=patient_C.tolist()\n",
    "    \n",
    "    patient_A_dtp=[]\n",
    "    patient_B_dtp=[]\n",
    "    patient_C_dtp=[]  \n",
    "    for elem in patient_A:\n",
    "        for i in range(sampling_rate):\n",
    "            patient_A_dtp.append(elem) \n",
    "    for elem in patient_B:\n",
    "        for i in range(sampling_rate):\n",
    "            patient_B_dtp.append(elem)\n",
    "        \n",
    "    for elem in patient_C:\n",
    "        for i in range(sampling_rate):\n",
    "            patient_C_dtp.append(elem)\n",
    "            \n",
    "    target_=pd.DataFrame({\"Diagnosis A\":patient_A_dtp,\"Diagnosis B\":patient_B_dtp,\"Diagnosis C\":patient_C_dtp})\n",
    "    \n",
    "    return target_  \n",
    "\n",
    "# Add a time column with the seconds\n",
    "def add_time(df):\n",
    "    list_time=[]\n",
    "    for i in range(len(df)):\n",
    "        list_time.append(i//sampling_rate)\n",
    "    df[\"time\"]=list_time\n",
    "    return df\n",
    "\n",
    "# Create target variables when seizures lasts at least 10\n",
    "def is_seizure(df):\n",
    "    \n",
    "    threshold = sampling_rate*10\n",
    "    \n",
    "    df['is_seizure_A'] = df[\"Diagnosis A\"].groupby((df[\"Diagnosis A\"] != df[\"Diagnosis A\"].shift()).cumsum()).transform('size') * df[\"Diagnosis A\"]\n",
    "    df['is_seizure_A'] = (df['is_seizure_A'] > threshold).astype(int)\n",
    "    \n",
    "    df['is_seizure_B'] = df[\"Diagnosis B\"].groupby((df[\"Diagnosis B\"] != df[\"Diagnosis B\"].shift()).cumsum()).transform('size') * df[\"Diagnosis B\"]\n",
    "    df['is_seizure_B'] = (df['is_seizure_B'] > threshold).astype(int)\n",
    "    \n",
    "    df['is_seizure_C'] = df[\"Diagnosis C\"].groupby((df[\"Diagnosis C\"] != df[\"Diagnosis C\"].shift()).cumsum()).transform('size') * df[\"Diagnosis C\"]\n",
    "    df['is_seizure_C'] = (df['is_seizure_C'] > threshold).astype(int)\n",
    "    \n",
    "    return df \n",
    "\n",
    "# Create final target\n",
    "def create_target(df):\n",
    "    df['is_seizure_target'] = np.where(df['is_seizure_A'] + df['is_seizure_B'] + df['is_seizure_C'] >= 2, 1, 0)\n",
    "    return df\n",
    "\n",
    "# Remove useless\n",
    "def remove_useless_columns(df):\n",
    "    df.drop(columns=['Diagnosis A', 'Diagnosis B', 'Diagnosis C', 'is_seizure_A', 'is_seizure_B', 'is_seizure_C', 'ECG EKG', 'Resp Effort', 'time'], inplace=True)\n",
    "    return df\n",
    "\n",
    "# Final function to label\n",
    "def label_data(path_raw_data, signals_preprocessed, n):\n",
    "    \n",
    "    signals, signal_headers, header = highlevel.read_edf(path_raw_data)\n",
    "    \n",
    "    names_ele = [signal_headers[iele]['label'] for iele in range(signals.shape[0])] # extract electrode names\n",
    "    \n",
    "    eeg_patient = eeg_formated(signals_preprocessed, names_ele) # format the ECG\n",
    "    eeg_patient.rename(columns={'ECG EKG-REF':'ECG EKG', 'Resp Effort-REF':'Resp Effort'}, inplace=True)\n",
    "    diagnosis_patient = diagnosis(n) # format the diagnosis\n",
    "    \n",
    "    data_patient = pd.merge(left=eeg_patient, right=diagnosis_patient, how='left', left_index=True, right_index=True) # merge ecg and diagnosis\n",
    "    \n",
    "    add_time(data_patient)\n",
    "    is_seizure(data_patient)\n",
    "    create_target(data_patient)\n",
    "    remove_useless_columns(data_patient)\n",
    "    \n",
    "    return data_patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30623872",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_input(df):\n",
    "    data = np.array((df.iloc[i:i+len_window+1]) for i in range(0,len(df)-len_window, overlap*sample_rate))\n",
    "    r=data.shape[0]\n",
    "    c=data.shape[1]\n",
    "    data = pd.DataFrame(data.reshape(r,c))\n",
    "    \n",
    "    X = data.iloc[:,:-1]\n",
    "    y = data.iloc[:,-1]\n",
    "    return X,y\n",
    "\n",
    "def oversampling(X, y): \n",
    "    sm = SMOTE(sampling_strategy='minority', random_state=7)\n",
    "    X, y = sm.fit_resample(X, y)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3e4f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_pipeline(path_raw_data, scaler, patient_number, Fournier=False):\n",
    "    \n",
    "    # Load raw data\n",
    "    signals, signal_headers, header = highlevel.read_edf(path_raw_data)\n",
    "    \n",
    "    # Preprocess data \n",
    "    signals_preprocessed = filter_signals(signals, sampling_rate, scaler, hp_frequency = 0.1, notch_frequency = 50, quality_factor = 30)\n",
    "    \n",
    "    if Fournier == True:\n",
    "        signals_preprocessed = pd.DataFrame(np.array([abs(rfft(signals_preprocessed[i])) for i in range(len(signals_preprocessed))]))\n",
    "        \n",
    "    # Label data\n",
    "    df = label_data(path_raw_data, signals_preprocessed, patient_number)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9398bda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = model_pipeline(\"../raw_data/eeg5.edf\",  MinMaxScaler(), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255db3b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30d50c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def redefine_window_target(window_df):\n",
    "    if len(np.unique(window_df.iloc[:,-1])) == 1:\n",
    "        target = window_df.iloc[0,-1]\n",
    "    elif np.unique(window_df.iloc[:,-1],return_counts=True)[1][1] >= 2*256:\n",
    "        target = 1\n",
    "    else:\n",
    "        target = 0\n",
    "    t_df = window_df.drop(columns = \"is_seizure_target\")\n",
    "    window = pd.DataFrame(np.array(t_df))\n",
    "    window[\"Target\"] = target\n",
    "    return window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da8cf4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array([redefine_window_target(df.iloc[i:i+len_window ]) for i in range(0,len(df)-len_window, overlap*sample_rate)])\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d74e308",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973125c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#r=data.shape[0]*data.shape[1]\n",
    "#c=data.shape[2]\n",
    "    \n",
    "#data = pd.DataFrame(data.reshape(r,c))\n",
    "X = data[:,:,:-1]\n",
    "y = data[:,:,-1]\n",
    "y=y.sum(axis=1)>=2#*256\n",
    "y = y.astype(int)\n",
    "index_seizure = []\n",
    "curr = 0\n",
    "for i, el in enumerate(y):\n",
    "    if curr == 0 and el == 1:\n",
    "        index_seizure.append(i)\n",
    "    curr = el\n",
    "past_length = 3\n",
    "for ind in index_seizure:\n",
    "    y[ind-past_length:ind] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9ee18d22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0],\n",
       "       [0, 0, 0],\n",
       "       [0, 0, 0],\n",
       "       [0, 0, 0],\n",
       "       [1, 1, 1],\n",
       "       [1, 1, 1],\n",
       "       [0, 0, 0],\n",
       "       [0, 0, 0],\n",
       "       [0, 0, 0],\n",
       "       [1, 1, 1],\n",
       "       [1, 1, 1],\n",
       "       [0, 0, 0],\n",
       "       [0, 0, 0]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "998c9dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=y.sum(axis=1)>=2#*256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4725d8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "bb5834e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "cc006212",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_seizure = []\n",
    "curr = 0\n",
    "for i, el in enumerate(y):\n",
    "    if curr == 0 and el == 1:\n",
    "        index_seizure.append(i)\n",
    "    curr = el"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b7d0c931",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 9]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_seizure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ad28dce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "past_length = 2\n",
    "for ind in index_seizure:\n",
    "    y[ind-past_length:ind] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6b9c8045",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 2, 2, 1, 1, 0, 2, 2, 1, 1, 0, 0])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6302ceae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def oversampling(X, y): \n",
    "    sm = SMOTE(sampling_strategy='minority', random_state=7)\n",
    "    X, y = sm.fit_resample(X, y)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34c9454",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_ind, test_ind = train_test_split(np.arange(767), test_size=0.2)\n",
    "\n",
    "X_train = X[train_ind,:,:]\n",
    "X_test = X[test_ind,:,:]\n",
    "y_train = y[train_ind]\n",
    "y_test = y[test_ind]\n",
    "\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2)\n",
    "    \n",
    "    # Balancing\n",
    "\n",
    "#X_train, y_train = oversampling(X_train, y_train)\n",
    "#y_train.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724e88a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc938780",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape #n.reshape((767, 2561, 19))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb818d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.SimpleRNN(units=10, activation='tanh',input_shape=(2561, 19)))\n",
    "model.add(layers.Dense(10, activation=\"relu\"))\n",
    "model.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "# The compilation\n",
    "model.compile(\n",
    "        optimizer='rmsprop',\n",
    "        loss='binary_crossentropy', \n",
    "        metrics=[ts.keras.metrics.Recall(),\"accuracy\"])\n",
    "\n",
    "# The fit\n",
    "model.fit(X_train, y_train,\n",
    "         batch_size=32,\n",
    "         epochs=50, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2699f2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_DL =model.evaluate(X_test, y_test)\n",
    "loss=results_DL[0]\n",
    "recall = results_DL[1]\n",
    "accuracy = results_DL[2]\n",
    "print(loss,recall,accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d531db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
