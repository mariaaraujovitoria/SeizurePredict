{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab4b515b",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Imports, variables, functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9de958e9",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# -- IMPORTS --\n",
    "\n",
    "import scipy.io\n",
    "from pyedflib import highlevel\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from itertools import groupby\n",
    "import csv\n",
    "import pickle\n",
    "from scipy.signal import butter, sosfilt, sosfiltfilt, sosfreqz\n",
    "from scipy.signal import freqz, iirnotch, filtfilt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "import random\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy import signal\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f900d3b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# -- ENVIRONMENT VARIABLES --\n",
    "\n",
    "sample_rate = sampling_rate = 256\n",
    "sec = 10\n",
    "len_window = sample_rate*sec\n",
    "overlap = 5\n",
    "threshold = 2*sample_rate\n",
    "sample_rate_downsample = int(0.1*sample_rate)\n",
    "len_window_downsample = sample_rate_downsample*sec\n",
    "\n",
    "# Patients\n",
    "patients = list(range(1,80))\n",
    "patient_with_issue = [4, 29, 50] # Can't import ECG4, ECG29 and ECG50\n",
    "for i in patient_with_issue:\n",
    "    patients.remove(i)\n",
    "\n",
    "# Load annotation file\n",
    "annt = scipy.io.loadmat('../raw_data/annotations_2017.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24bcfb30",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## -- PREPROCESSING FUNCTIONS --\n",
    "\n",
    "# Highpass filter\n",
    "def highpass_filter(signals, sampling_rate, hp_frequency = 0.1):\n",
    "    sos = butter(N = 3, Wn = hp_frequency, btype=\"highpass\",fs=sampling_rate, output=\"sos\")\n",
    "    filter_hp = sosfiltfilt(sos, signals)\n",
    "    return filter_hp\n",
    "\n",
    "# Powerline filter\n",
    "def notch_filter(signals, sampling_rate, notch_frequency = 50, quality_factor = 30):\n",
    "    w0 = notch_frequency/(sampling_rate/2)\n",
    "    b_notch, a_notch = iirnotch(w0, quality_factor)\n",
    "    filter_notch = filtfilt(b_notch, a_notch, signals, axis = -1)\n",
    "    return filter_notch\n",
    "\n",
    "# Create our own scaler\n",
    "class CustomTranformer(TransformerMixin, BaseEstimator): \n",
    "    # BaseEstimator generates the get_params() and set_params() methods that all Pipelines require\n",
    "    # TransformerMixin creates the fit_transform() method from fit() and transform()\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        self.means = X.mean()\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        norm_features = X - self.means\n",
    "        return norm_features\n",
    "\n",
    "# Combination of all filters and Scaler\n",
    "def filter_signals(signals, sampling_rate, scaler, hp_frequency = 0.1, notch_frequency = 50, quality_factor = 30):\n",
    "    filter_hp = highpass_filter(signals, sampling_rate)\n",
    "    filter_notch = notch_filter(filter_hp, sampling_rate, notch_frequency, quality_factor)\n",
    "    final_signal = scaler.fit_transform(filter_notch)\n",
    "    return final_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9294b525",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## -- LABEL FUNCTIONS --\n",
    "\n",
    "# Format the EEG \n",
    "def eeg_formated(signals, names_ele):\n",
    "    data_signals = signals.T # transpose the signals from datapoints\n",
    "    data_signals = pd.DataFrame(data_signals) # create a pandas dataframe\n",
    "    \n",
    "    data_signals.columns = names_ele # rename columns\n",
    "    \n",
    "    return data_signals\n",
    "\n",
    "# Format the annotations\n",
    "def diagnosis(n):\n",
    "    patient_A=annt[\"annotat_new\"][0][n-1][0]\n",
    "    patient_B=annt[\"annotat_new\"][0][n-1][1]\n",
    "    patient_C=annt[\"annotat_new\"][0][n-1][2]\n",
    "    \n",
    "    #converting seconds to datapoints\n",
    "\n",
    "    patient_A=patient_A.tolist()\n",
    "    patient_B=patient_B.tolist()\n",
    "    patient_C=patient_C.tolist()\n",
    "    \n",
    "    patient_A_dtp=[]\n",
    "    patient_B_dtp=[]\n",
    "    patient_C_dtp=[]  \n",
    "    for elem in patient_A:\n",
    "        for i in range(sampling_rate):\n",
    "            patient_A_dtp.append(elem) \n",
    "    for elem in patient_B:\n",
    "        for i in range(sampling_rate):\n",
    "            patient_B_dtp.append(elem)\n",
    "        \n",
    "    for elem in patient_C:\n",
    "        for i in range(sampling_rate):\n",
    "            patient_C_dtp.append(elem)\n",
    "            \n",
    "    target_=pd.DataFrame({\"Diagnosis A\":patient_A_dtp,\"Diagnosis B\":patient_B_dtp,\"Diagnosis C\":patient_C_dtp})\n",
    "    \n",
    "    return target_  \n",
    "\n",
    "# Create target variables when seizures lasts at least 10\n",
    "def is_seizure(df):\n",
    "    \n",
    "    threshold = sampling_rate*10\n",
    "    \n",
    "    df['is_seizure_A'] = df[\"Diagnosis A\"].groupby((df[\"Diagnosis A\"] != df[\"Diagnosis A\"].shift()).cumsum()).transform('size') * df[\"Diagnosis A\"]\n",
    "    df['is_seizure_A'] = (df['is_seizure_A'] > threshold).astype(int)\n",
    "    \n",
    "    df['is_seizure_B'] = df[\"Diagnosis B\"].groupby((df[\"Diagnosis B\"] != df[\"Diagnosis B\"].shift()).cumsum()).transform('size') * df[\"Diagnosis B\"]\n",
    "    df['is_seizure_B'] = (df['is_seizure_B'] > threshold).astype(int)\n",
    "    \n",
    "    df['is_seizure_C'] = df[\"Diagnosis C\"].groupby((df[\"Diagnosis C\"] != df[\"Diagnosis C\"].shift()).cumsum()).transform('size') * df[\"Diagnosis C\"]\n",
    "    df['is_seizure_C'] = (df['is_seizure_C'] > threshold).astype(int)\n",
    "    \n",
    "    return df \n",
    "\n",
    "# Create final target\n",
    "def create_target(df):\n",
    "    df['is_seizure_target'] = np.where(df['is_seizure_A'] + df['is_seizure_B'] + df['is_seizure_C'] >= 2, 1, 0)\n",
    "    return df\n",
    "\n",
    "# Remove useless\n",
    "def remove_useless_columns(df):\n",
    "    df.drop(columns=['Diagnosis A', 'Diagnosis B', 'Diagnosis C', 'is_seizure_A', 'is_seizure_B', 'is_seizure_C', 'ECG EKG', 'Resp Effort'], inplace=True)\n",
    "    return df\n",
    "\n",
    "# Final function to label\n",
    "def label_data(path_raw_data, signals_preprocessed, n):\n",
    "    \n",
    "    signals, signal_headers, header = highlevel.read_edf(path_raw_data)\n",
    "    \n",
    "    names_ele = [signal_headers[iele]['label'] for iele in range(signals.shape[0])] # extract electrode names\n",
    "    \n",
    "    eeg_patient = eeg_formated(signals_preprocessed, names_ele) # format the ECG\n",
    "    eeg_patient.rename(columns={'ECG EKG-REF':'ECG EKG', 'Resp Effort-REF':'Resp Effort'}, inplace=True)\n",
    "    \n",
    "    diagnosis_patient = diagnosis(n) # format the diagnosis\n",
    "    \n",
    "    data_patient = pd.merge(left=eeg_patient, right=diagnosis_patient, how='left', left_index=True, right_index=True) # merge ecg and diagnosis\n",
    "    \n",
    "    is_seizure(data_patient)\n",
    "    create_target(data_patient)\n",
    "    remove_useless_columns(data_patient)\n",
    "    \n",
    "    return data_patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb71dc91",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## -- FEATURE ENGINEERING --\n",
    "\n",
    "def flatten(window_df):\n",
    "    if len(np.unique(window_df.iloc[:,-1])) == 1:\n",
    "        target = window_df.iloc[0,-1]\n",
    "    elif np.unique(window_df.iloc[:,-1],return_counts=True)[1][1] >= threshold:\n",
    "        target = 1\n",
    "    else:\n",
    "        target = 0\n",
    "    t_df = window_df.drop(columns = \"target\").transpose()\n",
    "    flatten = pd.DataFrame(np.array(t_df).reshape(1,t_df.shape[0]*t_df.shape[1]))\n",
    "    flatten[\"Target\"] = target\n",
    "    return flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d80e8071",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## -- MAIN FUNCTIONS --\n",
    "\n",
    "def preprocess_and_label(path_raw_data, scaler, patient_number, Fournier=False):\n",
    "    \n",
    "    # Load raw data\n",
    "    signals, signal_headers, header = highlevel.read_edf(path_raw_data)\n",
    "    \n",
    "    # Preprocess data \n",
    "    signals_preprocessed = filter_signals(signals, sampling_rate, scaler, hp_frequency = 0.1, notch_frequency = 50, quality_factor = 30)\n",
    "    \n",
    "    if Fournier == True:\n",
    "        signals_preprocessed = pd.DataFrame(np.array([abs(rfft(signals_preprocessed[i])) for i in range(len(signals_preprocessed))]))\n",
    "        \n",
    "    # Label data\n",
    "    df = label_data(path_raw_data, signals_preprocessed, patient_number)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def downsampling(df):\n",
    "    df_downsample = pd.DataFrame()\n",
    "    all_df = pd.DataFrame()\n",
    "    target_col = df.iloc[:,-1]\n",
    "    num = int(0.1*sample_rate)\n",
    "    t = 256\n",
    "    for i, column in enumerate(df.columns[:-1]):\n",
    "        df_downsample = pd.DataFrame()\n",
    "        for j in range(0,len(df)-sample_rate,sample_rate):\n",
    "            x = np.array(df.iloc[j:j+sample_rate,i])\n",
    "            x_resampled = pd.DataFrame(signal.resample(x, num), index=range(int(j/10),int(j/10)+num))\n",
    "            df_downsample= pd.concat([df_downsample,x_resampled])\n",
    "        all_df[column] = np.array(df_downsample).reshape(1,-1)[0]\n",
    "    target = []\n",
    "    for t in range(0,len(target_col)-256,sample_rate):\n",
    "        for n in range(num):\n",
    "            target.append(target_col[t])\n",
    "    all_df[\"target\"] = target\n",
    "    return all_df\n",
    "\n",
    "def flatten_dataframe(df):\n",
    "    data = np.array([flatten(df.iloc[i:i+len_window_downsample]) for i in range(0,len(df)-len_window_downsample, overlap*sample_rate_downsample)])\n",
    "    r=data.shape[0]\n",
    "    c=data.shape[2]\n",
    "    data = pd.DataFrame(data.reshape(r,c))\n",
    "    return data\n",
    "\n",
    "def concat_dataframes(dictionnary_of_dataframes):\n",
    "    df = pd.concat([dictionnary_of_dataframes[i] for i in dictionnary_of_dataframes.keys()])\n",
    "    return df\n",
    "\n",
    "def create_x_and_y(df):\n",
    "    X = df.iloc[:,:-1]\n",
    "    y = df.iloc[:,-1]\n",
    "    return X,y\n",
    "\n",
    "def oversampling(X, y): \n",
    "    sm = SMOTE(sampling_strategy='minority', random_state=7)\n",
    "    X, y = sm.fit_resample(X, y)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72adac94",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c44d901e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "d = {}\n",
    "for i in patients:\n",
    "    df_i = preprocess_and_label(f\"../raw_data/eeg{i}.edf\", CustomTranformer(), i, Fournier=False)\n",
    "    df_i = downsampling(df_i)\n",
    "    df_i = flatten_dataframe(df_i)\n",
    "    d[i] = df_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "032324ad",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Create train and test for patient 5\n",
    "df_5_test = d[5].iloc[260:490, :]\n",
    "\n",
    "df_5_train = d[5].iloc[:260, :]\n",
    "df_5_train = pd.concat([df_5_train, d[5].iloc[490:,:]])\n",
    "\n",
    "X_train_5, y_train_5 = create_x_and_y(df_5_train)\n",
    "X_test_5, y_test_5 = create_x_and_y(df_5_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "01f532f1",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Create final dataframe\n",
    "d_without_5 = d.copy()\n",
    "del d_without_5[5]\n",
    "df = concat_dataframes(d_without_5)\n",
    "X, y = create_x_and_y(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a7424062",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "X_train = pd.concat([X_train, X_train_5])\n",
    "y_train = pd.concat([y_train, y_train_5])\n",
    "\n",
    "X_test = pd.concat([X_test, X_test_5])\n",
    "y_test = pd.concat([y_test, y_test_5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "544e4e7c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#X_train.to_csv('../data_modeling/X_train.csv')\n",
    "#y_train.to_csv('../data_modeling/y_train.csv')\n",
    "#X_test.to_csv('../data_modeling/X_test.csv')\n",
    "#y_test.to_csv('../data_modeling/y_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4c376c63",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Balance the data\n",
    "undersample = RandomUnderSampler()\n",
    "\n",
    "X_train, y_train = undersample.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8caa07d5",
   "metadata": {},
   "source": [
    "# Modeling default Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "9514fb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(max_depth=10, min_samples_split=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "751d7d02",
   "metadata": {},
   "source": [
    "## Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "ac82e2b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=10, min_samples_split=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=10, min_samples_split=10)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(max_depth=10, min_samples_split=10)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "1f0e5b9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9170555108608206"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train accuracy \n",
    "y_pred_train = model.predict(X_train)\n",
    "\n",
    "train_score = accuracy_score(y_train, y_pred_train)\n",
    "train_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f86151b",
   "metadata": {},
   "source": [
    "## Test on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "a8e70e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.63      0.76     20169\n",
      "         1.0       0.21      0.76      0.33      2681\n",
      "\n",
      "    accuracy                           0.64     22850\n",
      "   macro avg       0.58      0.70      0.55     22850\n",
      "weighted avg       0.87      0.64      0.71     22850\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test accuracy\n",
    "y_pred_test = model.predict(X_test)\n",
    "\n",
    "test_score = classification_report(y_test, y_pred_test)\n",
    "\n",
    "print(test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "fa7ffbf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>predicted</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>12651</td>\n",
       "      <td>7518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>632</td>\n",
       "      <td>2049</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "predicted    0.0   1.0\n",
       "actual                \n",
       "0.0        12651  7518\n",
       "1.0          632  2049"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confusion matrix\n",
    "test_results_df = pd.DataFrame({\"actual\": y_test,\n",
    "                           \"predicted\": y_pred_test})\n",
    "    \n",
    "test_confusion_matrix = pd.crosstab(index= test_results_df['actual'],\n",
    "                               columns = test_results_df['predicted'])\n",
    "    \n",
    "test_confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbcb3057",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Test on patient 5: all data (not relevant because part of the data is used for training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "f4e90cb9",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Preprocess and label new data\n",
    "path_raw_new_data = \"../raw_data/eeg5.edf\"\n",
    "df_new = preprocess_and_label(path_raw_new_data, CustomTranformer(), 5, Fournier=False)\n",
    "\n",
    "# Downsampling new data\n",
    "df_new_downsample = downsampling(df_new)\n",
    "\n",
    "# Flatten new data\n",
    "df_new_downsample_flat = flatten_dataframe(df_new_downsample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "698d4111",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.47      0.75      0.58       132\n",
      "         1.0       0.94      0.82      0.88       634\n",
      "\n",
      "    accuracy                           0.81       766\n",
      "   macro avg       0.70      0.79      0.73       766\n",
      "weighted avg       0.86      0.81      0.83       766\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Accuracy\n",
    "y_true = df_new_downsample_flat.iloc[:,-1]\n",
    "y_pred = model.predict(df_new_downsample_flat.iloc[:,:-1])\n",
    "\n",
    "new_score = classification_report(y_true, y_pred)\n",
    "print(new_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "3c8188f0",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>predicted</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>99</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>112</td>\n",
       "      <td>522</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "predicted  0.0  1.0\n",
       "actual             \n",
       "0.0         99   33\n",
       "1.0        112  522"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confusion matrix\n",
    "new_results_df = pd.DataFrame({\"actual\": y_true,\n",
    "                           \"predicted\": y_pred})\n",
    "    \n",
    "new_confusion_matrix = pd.crosstab(index= new_results_df['actual'],\n",
    "                               columns = new_results_df['predicted'])\n",
    "    \n",
    "new_confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc4d572",
   "metadata": {},
   "source": [
    "## Test on patient 5: only the test from patient 5 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "85ce76ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.23      0.69      0.34        48\n",
      "         1.0       0.83      0.39      0.53       182\n",
      "\n",
      "    accuracy                           0.45       230\n",
      "   macro avg       0.53      0.54      0.44       230\n",
      "weighted avg       0.70      0.45      0.49       230\n",
      "\n"
     ]
    }
   ],
   "source": [
    "score_specific_window = classification_report(y_test_5, model.predict(X_test_5))\n",
    "print(score_specific_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "a34e04a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>predicted</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>33</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>111</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "predicted  0.0  1.0\n",
       "actual             \n",
       "0.0         33   15\n",
       "1.0        111   71"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confusion matrix\n",
    "new_results_df = pd.DataFrame({\"actual\": y_test_5,\n",
    "                           \"predicted\": model.predict(X_test_5)})\n",
    "    \n",
    "new_confusion_matrix = pd.crosstab(index= new_results_df['actual'],\n",
    "                               columns = new_results_df['predicted'])\n",
    "    \n",
    "new_confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0fd2110",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Finetune the model: RandomSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "14a839a2",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/florencetersier/.pyenv/versions/3.10.6/envs/SeizurePredict/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:700: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [98], line 30\u001b[0m\n\u001b[1;32m     24\u001b[0m search \u001b[38;5;241m=\u001b[39m RandomizedSearchCV(model, random_grid, \n\u001b[1;32m     25\u001b[0m                             scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecall\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     26\u001b[0m                             n_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m,  \n\u001b[1;32m     27\u001b[0m                             cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Fit data to Random Grid\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m \u001b[43msearch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/SeizurePredict/lib/python3.10/site-packages/sklearn/model_selection/_search.py:875\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    869\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    870\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    871\u001b[0m     )\n\u001b[1;32m    873\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 875\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    878\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    879\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/SeizurePredict/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1753\u001b[0m, in \u001b[0;36mRandomizedSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1751\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1752\u001b[0m     \u001b[38;5;124;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1753\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1754\u001b[0m \u001b[43m        \u001b[49m\u001b[43mParameterSampler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1755\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_distributions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\n\u001b[1;32m   1756\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1757\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/SeizurePredict/lib/python3.10/site-packages/sklearn/model_selection/_search.py:822\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    814\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    815\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    816\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    817\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    818\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    819\u001b[0m         )\n\u001b[1;32m    820\u001b[0m     )\n\u001b[0;32m--> 822\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    823\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    828\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    829\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    830\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    831\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    832\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    833\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    835\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    836\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    837\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    839\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    840\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    841\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    842\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    843\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    844\u001b[0m     )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/SeizurePredict/lib/python3.10/site-packages/joblib/parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1095\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1097\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1098\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_time\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/SeizurePredict/lib/python3.10/site-packages/joblib/parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    973\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    974\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupports_timeout\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m--> 975\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(\u001b[43mjob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    976\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    977\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget())\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/SeizurePredict/lib/python3.10/site-packages/joblib/_parallel_backends.py:567\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[38;5;124;03m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[1;32m    565\u001b[0m \u001b[38;5;124;03mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[1;32m    566\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 567\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    568\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CfTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    569\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/lib/python3.10/concurrent/futures/_base.py:453\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m    451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[0;32m--> 453\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_condition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[1;32m    456\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/lib/python3.10/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "search = RandomizedSearchCV(model, random_grid, \n",
    "                            scoring='recall',\n",
    "                            n_iter=100,  \n",
    "                            cv=5, n_jobs=-1)\n",
    "\n",
    "# Fit data to Random Grid\n",
    "search.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5772cb8",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Best score\n",
    "search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca5097d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Best Params\n",
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e05211",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Best estimator\n",
    "search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca0b139",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Modeling finetuned RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df707bc",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model_ft = RandomForestClassifier() #change hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539cec27",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b588bf96",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "model_ft.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab99408",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Train accuracy \n",
    "y_pred_train = model_ft.predict(X_train)\n",
    "\n",
    "train_score = accuracy_score(y_train, y_pred_train)\n",
    "train_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5503157",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Test on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d20020e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Test accuracy\n",
    "y_pred_test = model_ft.predict(X_test)\n",
    "\n",
    "test_score = accuracy_score(y_test, y_pred_test)\n",
    "test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e3d64f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "test_results_df = pd.DataFrame({\"actual\": y_test,\n",
    "                           \"predicted\": y_pred_test})\n",
    "    \n",
    "test_confusion_matrix = pd.crosstab(index= test_results_df['actual'],\n",
    "                               columns = test_results_df['predicted'])\n",
    "    \n",
    "test_confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3751049",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Test on new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc5b17b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "y_true = df_new_downsample_flat.iloc[:,-1]\n",
    "y_pred = model_ft.predict(df_new_downsample_flat.iloc[:,:-1])\n",
    "\n",
    "new_score = accuracy_score(y_true, y_pred)\n",
    "new_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45901792",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "new_results_df = pd.DataFrame({\"actual\": y_true,\n",
    "                           \"predicted\": y_pred})\n",
    "    \n",
    "new_confusion_matrix = pd.crosstab(index= new_results_df['actual'],\n",
    "                               columns = new_results_df['predicted'])\n",
    "    \n",
    "new_confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3340d49b",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Test on patient 5 specific window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168fe9da",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "score_specific_window = classification_report(y_test_5, model_ft.predict(X_test_5))\n",
    "print(score_specific_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fefc54",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "new_results_df = pd.DataFrame({\"actual\": y_test_5,\n",
    "                           \"predicted\": model_ft.predict(X_test_5)})\n",
    "    \n",
    "new_confusion_matrix = pd.crosstab(index= new_results_df['actual'],\n",
    "                               columns = new_results_df['predicted'])\n",
    "    \n",
    "new_confusion_matrix"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
